#!/usr/bin/env python3
"""
æµ‹è¯•åŠ¨æ€å›¾ç‰‡URLè¯†åˆ«åŠŸèƒ½

æµ‹è¯•å„ç§ç±»å‹çš„å›¾ç‰‡URLï¼ŒåŒ…æ‹¬ï¼š
1. ä¼ ç»Ÿçš„å¸¦æ‰©å±•åçš„å›¾ç‰‡URL
2. åŠ¨æ€ç”Ÿæˆçš„å›¾ç‰‡URLï¼ˆæ— æ‰©å±•åï¼‰
3. APIé£æ ¼çš„å›¾ç‰‡URL
4. CDNå›¾ç‰‡URL
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from crawler.utils.url_parser import URLParser
from crawler.core.downloader import ImageDownloader


def test_url_recognition():
    """æµ‹è¯•URLè¯†åˆ«åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•å›¾ç‰‡URLè¯†åˆ«åŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºURLè§£æå™¨
    parser = URLParser("https://example.com")
    
    # æµ‹è¯•URLåˆ—è¡¨
    test_urls = [
        # ä¼ ç»Ÿå›¾ç‰‡URL
        ("https://example.com/image.jpg", "ä¼ ç»ŸJPGå›¾ç‰‡"),
        ("https://example.com/photo.png", "ä¼ ç»ŸPNGå›¾ç‰‡"),
        ("https://example.com/picture.gif", "ä¼ ç»ŸGIFå›¾ç‰‡"),
        
        # åŠ¨æ€å›¾ç‰‡URLï¼ˆæ‚¨æåˆ°çš„ä¾‹å­ï¼‰
        ("https://haowallpaper.com/link/common/file/getCroppingImg/17044056264658304", "åŠ¨æ€è£å‰ªå›¾ç‰‡"),
        ("https://haowallpaper.com/link/common/file/getCroppingImg/17112428137401728", "åŠ¨æ€è£å‰ªå›¾ç‰‡2"),
        
        # å…¶ä»–åŠ¨æ€å›¾ç‰‡URLæ¨¡å¼
        ("https://api.example.com/v1/image/12345", "APIé£æ ¼å›¾ç‰‡"),
        ("https://cdn.example.com/getImage/67890", "CDNå›¾ç‰‡"),
        ("https://example.com/thumbnail/98765", "ç¼©ç•¥å›¾"),
        ("https://example.com/resize/400x300/image123", "è°ƒæ•´å°ºå¯¸å›¾ç‰‡"),
        ("https://example.com/avatar/user_456789", "ç”¨æˆ·å¤´åƒ"),
        ("https://example.com/wallpaper/nature_12345", "å£çº¸"),
        
        # CDNå’Œäº‘å­˜å‚¨
        ("https://d1234567890.cloudfront.net/images/photo123", "CloudFront CDN"),
        ("https://bucket.s3.amazonaws.com/images/pic.jpg", "AWS S3"),
        
        # éå›¾ç‰‡URLï¼ˆåº”è¯¥è¢«æ’é™¤ï¼‰
        ("https://example.com/page.html", "HTMLé¡µé¢"),
        ("https://example.com/script.js", "JavaScriptæ–‡ä»¶"),
        ("https://example.com/ads/banner.jpg", "å¹¿å‘Šå›¾ç‰‡ï¼ˆåº”æ’é™¤ï¼‰"),
        ("https://example.com/thumb_small.jpg", "ç¼©ç•¥å›¾ï¼ˆåº”æ’é™¤ï¼‰"),
    ]
    
    print("åŸºç¡€æ¨¡å¼åŒ¹é…æµ‹è¯•:")
    print("-" * 40)
    
    for url, description in test_urls:
        is_image_basic = parser.is_image_url(url, check_content_type=False)
        print(f"{'âœ…' if is_image_basic else 'âŒ'} {description}")
        print(f"   URL: {url}")
        print(f"   åŸºç¡€è¯†åˆ«: {is_image_basic}")
        print()


async def test_content_type_detection():
    """æµ‹è¯•å†…å®¹ç±»å‹æ£€æµ‹åŠŸèƒ½"""
    print("\nğŸŒ æµ‹è¯•å†…å®¹ç±»å‹æ£€æµ‹åŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºURLè§£æå™¨
    parser = URLParser("https://example.com")
    
    # çœŸå®çš„å›¾ç‰‡URLï¼ˆç”¨äºæµ‹è¯•å†…å®¹ç±»å‹æ£€æµ‹ï¼‰
    real_image_urls = [
        ("https://httpbin.org/image/jpeg", "HTTPBin JPEGå›¾ç‰‡"),
        ("https://httpbin.org/image/png", "HTTPBin PNGå›¾ç‰‡"),
        ("https://httpbin.org/image/webp", "HTTPBin WebPå›¾ç‰‡"),
        # æ‚¨æåˆ°çš„çœŸå®URL
        ("https://haowallpaper.com/link/common/file/getCroppingImg/17044056264658304", "å“²é£å£çº¸åŠ¨æ€å›¾ç‰‡"),
    ]
    
    print("å†…å®¹ç±»å‹æ£€æµ‹æµ‹è¯•:")
    print("-" * 40)
    
    for url, description in real_image_urls:
        try:
            is_image_basic = parser.is_image_url(url, check_content_type=False)
            is_image_with_check = parser.is_image_url(url, check_content_type=True)
            
            print(f"ğŸ“· {description}")
            print(f"   URL: {url}")
            print(f"   åŸºç¡€è¯†åˆ«: {'âœ…' if is_image_basic else 'âŒ'}")
            print(f"   å†…å®¹æ£€æµ‹: {'âœ…' if is_image_with_check else 'âŒ'}")
            print()
            
        except Exception as e:
            print(f"âŒ {description}: æ£€æµ‹å¤±è´¥ - {e}")
            print()


async def test_download_dynamic_images():
    """æµ‹è¯•ä¸‹è½½åŠ¨æ€å›¾ç‰‡"""
    print("\nâ¬‡ï¸ æµ‹è¯•ä¸‹è½½åŠ¨æ€å›¾ç‰‡")
    print("=" * 60)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ImageDownloader("test_downloads")
    
    # æµ‹è¯•ä¸‹è½½çš„URL
    download_urls = [
        "https://httpbin.org/image/jpeg",
        "https://httpbin.org/image/png",
        # å¦‚æœæ‚¨æœ‰å¯è®¿é—®çš„åŠ¨æ€å›¾ç‰‡URLï¼Œå¯ä»¥æ·»åŠ åˆ°è¿™é‡Œ
        # "https://haowallpaper.com/link/common/file/getCroppingImg/17044056264658304",
    ]
    
    for url in download_urls:
        try:
            print(f"ğŸ“¥ ä¸‹è½½: {url}")
            result = await downloader.download_image(url)
            
            if result['success']:
                print(f"   âœ… ä¸‹è½½æˆåŠŸ")
                print(f"   ğŸ“ æ–‡ä»¶: {result['local_path']}")
                print(f"   ğŸ“ å°ºå¯¸: {result['width']}x{result['height']}")
                print(f"   ğŸ“„ æ ¼å¼: {result['format']}")
                print(f"   ğŸ’¾ å¤§å°: {result['file_size']} bytes")
            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: {result['error']}")
            
            print()
            
        except Exception as e:
            print(f"   âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            print()
    
    # downloader.close()  # ImageDownloaderæ²¡æœ‰closeæ–¹æ³•


def test_url_patterns():
    """æµ‹è¯•URLæ¨¡å¼åŒ¹é…"""
    print("\nğŸ” æµ‹è¯•URLæ¨¡å¼åŒ¹é…")
    print("=" * 60)
    
    parser = URLParser("https://example.com")
    
    # æµ‹è¯•å„ç§åŠ¨æ€å›¾ç‰‡URLæ¨¡å¼
    dynamic_patterns = [
        "https://site.com/getCroppingImg/123456",
        "https://site.com/getImage/789012",
        "https://site.com/api/v1/image/345678",
        "https://site.com/thumbnail/901234",
        "https://site.com/resize/567890",
        "https://site.com/crop/123789",
        "https://site.com/photo/456012",
        "https://site.com/picture/789345",
        "https://site.com/wallpaper/012678",
        "https://site.com/avatar/345901",
        "https://site.com/cover/678234",
        "https://site.com/banner/901567",
        "https://cdn.cloudfront.net/images/890123",
        "https://bucket.amazonaws.com/photos/234567.jpg",
    ]
    
    print("åŠ¨æ€URLæ¨¡å¼åŒ¹é…:")
    print("-" * 30)
    
    for url in dynamic_patterns:
        is_match = parser.is_image_url(url, check_content_type=False)
        print(f"{'âœ…' if is_match else 'âŒ'} {url}")
    
    print()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ–¼ï¸ åŠ¨æ€å›¾ç‰‡URLè¯†åˆ«æµ‹è¯•")
    print("=" * 80)
    
    # 1. æµ‹è¯•URLè¯†åˆ«
    test_url_recognition()
    
    # 2. æµ‹è¯•URLæ¨¡å¼
    test_url_patterns()
    
    # 3. æµ‹è¯•å†…å®¹ç±»å‹æ£€æµ‹
    await test_content_type_detection()
    
    # 4. æµ‹è¯•ä¸‹è½½åŠŸèƒ½
    await test_download_dynamic_images()
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. å¯¹äºå·²çŸ¥çš„åŠ¨æ€å›¾ç‰‡URLæ¨¡å¼ï¼Œå·²æ·»åŠ åˆ°URL_PATTERNSä¸­")
    print("2. å¯¹äºæœªçŸ¥æ¨¡å¼ï¼Œå¯ç”¨check_content_type=Trueè¿›è¡Œå†…å®¹æ£€æµ‹")
    print("3. ä¸‹è½½å™¨ä¼šè‡ªåŠ¨æ ¹æ®Content-Typeç¡®å®šæ­£ç¡®çš„æ–‡ä»¶æ‰©å±•å")


if __name__ == "__main__":
    asyncio.run(main())
