# å›¾åƒçˆ¬è™«åˆ†å¸ƒå¼é«˜å¯ç”¨ç³»ç»Ÿéƒ¨ç½²å’Œæ•…éšœæ’æŸ¥æŒ‡å—

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚

#### ç¡¬ä»¶è¦æ±‚
- **ä¸»æœåŠ¡å™¨**: 4æ ¸CPU, 8GBå†…å­˜, 100GBå­˜å‚¨
- **å¤‡æœåŠ¡å™¨**: 4æ ¸CPU, 8GBå†…å­˜, 100GBå­˜å‚¨
- **ç½‘ç»œ**: ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼Œå»¶è¿Ÿ < 50ms

#### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04+ / CentOS 8+ / Windows 10+
- **Python**: 3.8+
- **PostgreSQL**: 16+
- **ç½‘ç»œç«¯å£**: 5432(PostgreSQL), 8000(ä¸»API), 8001(HA API)

### éƒ¨ç½²æ­¥éª¤

#### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…Pythonå’Œpip
sudo apt install python3 python3-pip python3-venv -y

# å®‰è£…PostgreSQL
sudo apt install postgresql postgresql-contrib -y

# å¯åŠ¨PostgreSQLæœåŠ¡
sudo systemctl start postgresql
sudo systemctl enable postgresql
```

#### 2. æ•°æ®åº“é…ç½®

```bash
# åˆ‡æ¢åˆ°postgresç”¨æˆ·
sudo -u postgres psql

# åœ¨PostgreSQLä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤
CREATE DATABASE image_crawler;
CREATE USER postgres WITH PASSWORD 'Abcdefg6';
GRANT ALL PRIVILEGES ON DATABASE image_crawler TO postgres;
ALTER USER postgres CREATEDB;
\q
```

#### 3. é¡¹ç›®éƒ¨ç½²

```bash
# å…‹éš†é¡¹ç›®ï¼ˆæˆ–è§£å‹é¡¹ç›®æ–‡ä»¶ï¼‰
cd /opt
git clone <project-repository> image_crawler
cd image_crawler

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p logs data/images data/backup
```

#### 4. é…ç½®æ–‡ä»¶è®¾ç½®

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿
cp config/distributed_ha_config.yaml.example config/distributed_ha_config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
nano config/distributed_ha_config.yaml
```

**å…³é”®é…ç½®é¡¹**:
```yaml
# ä¿®æ”¹æ•°æ®åº“è¿æ¥ä¿¡æ¯
nodes:
  primary_node:
    server:
      host: "113.29.231.99"  # ä¸»æœåŠ¡å™¨IP
    database_url: "postgresql://postgres:Abcdefg6@113.29.231.99:5432/image_crawler"
  
  backup_node:
    server:
      host: "113.29.232.245"  # å¤‡æœåŠ¡å™¨IP
    database_url: "postgresql://postgres:Abcdefg6@113.29.232.245:5432/image_crawler"
```

#### 5. æ•°æ®åº“åˆå§‹åŒ–

```bash
# è¿è¡Œæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
python setup_postgresql_databases.py

# éªŒè¯æ•°æ®åº“è¿æ¥
python -c "
from config.ha_config_loader import load_ha_config
from sqlalchemy import create_engine, text

nodes, local_node_name, config = load_ha_config()
for node in nodes:
    try:
        engine = create_engine(node.database_url)
        with engine.connect() as conn:
            conn.execute(text('SELECT 1'))
        print(f'âœ… {node.name} è¿æ¥æˆåŠŸ')
    except Exception as e:
        print(f'âŒ {node.name} è¿æ¥å¤±è´¥: {e}')
"
```

#### 6. å¯åŠ¨ç³»ç»Ÿ

```bash
# å¯åŠ¨åˆ†å¸ƒå¼é«˜å¯ç”¨ç³»ç»Ÿ
python start_simple_ha.py
```

#### 7. éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
curl http://localhost:8000/api/ha-status
curl http://localhost:8001/api/status

# æ£€æŸ¥æ—¥å¿—
tail -f logs/simple_ha.log
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥æŒ‡å—

### å¸¸è§é—®é¢˜è¯Šæ–­

#### 1. æ•°æ®åº“è¿æ¥é—®é¢˜

**ç—‡çŠ¶**: ç³»ç»Ÿå¯åŠ¨æ—¶æŠ¥æ•°æ®åº“è¿æ¥å¤±è´¥

**è¯Šæ–­æ­¥éª¤**:
```bash
# æ£€æŸ¥PostgreSQLæœåŠ¡çŠ¶æ€
sudo systemctl status postgresql

# æ£€æŸ¥ç«¯å£ç›‘å¬
netstat -tlnp | grep 5432

# æµ‹è¯•æœ¬åœ°è¿æ¥
psql -h localhost -U postgres -d image_crawler

# æµ‹è¯•è¿œç¨‹è¿æ¥
psql -h 113.29.231.99 -U postgres -d image_crawler
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä¿®æ”¹PostgreSQLé…ç½®å…è®¸è¿œç¨‹è¿æ¥
sudo nano /etc/postgresql/16/main/postgresql.conf
# æ·»åŠ æˆ–ä¿®æ”¹: listen_addresses = '*'

sudo nano /etc/postgresql/16/main/pg_hba.conf
# æ·»åŠ : host all all 0.0.0.0/0 md5

# é‡å¯PostgreSQL
sudo systemctl restart postgresql

# æ£€æŸ¥é˜²ç«å¢™
sudo ufw allow 5432
```

#### 2. æ•…éšœè½¬ç§»ä¸å·¥ä½œ

**ç—‡çŠ¶**: ä¸»æ•°æ®åº“æ•…éšœæ—¶ç³»ç»Ÿæ²¡æœ‰è‡ªåŠ¨åˆ‡æ¢

**è¯Šæ–­æ­¥éª¤**:
```bash
# æ£€æŸ¥HAç®¡ç†å™¨çŠ¶æ€
curl http://localhost:8001/api/status

# æŸ¥çœ‹ç›‘æ§æ—¥å¿—
grep "æ•…éšœè½¬ç§»\|failover" logs/simple_ha.log

# æ£€æŸ¥èŠ‚ç‚¹å¥åº·çŠ¶æ€
curl http://localhost:8001/api/health
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„æ•…éšœè½¬ç§»è®¾ç½®
grep -A 5 "auto_failover" config/distributed_ha_config.yaml

# æ‰‹åŠ¨è§¦å‘æ•…éšœè½¬ç§»æµ‹è¯•
curl -X POST http://localhost:8001/api/failover \
  -H "Content-Type: application/json" \
  -d '{"source_node": "primary_node", "target_node": "backup_node"}'
```

#### 3. æ•°æ®åŒæ­¥å»¶è¿Ÿ

**ç—‡çŠ¶**: ä¸»å¤‡æ•°æ®åº“æ•°æ®ä¸ä¸€è‡´

**è¯Šæ–­æ­¥éª¤**:
```bash
# æ£€æŸ¥åŒæ­¥çŠ¶æ€
curl http://localhost:8001/api/sync-status

# æŸ¥çœ‹åŒæ­¥é˜Ÿåˆ—
curl http://localhost:8001/api/sync-queue

# æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
python -c "
from database.distributed_ha_manager import DistributedHAManager
from config.ha_config_loader import load_ha_config

nodes, local_node_name, config = load_ha_config()
ha_manager = DistributedHAManager(nodes, local_node_name, config)
result = ha_manager.check_data_consistency()
print(f'æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ: {result}')
"
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ‰‹åŠ¨è§¦å‘å…¨é‡åŒæ­¥
curl -X POST http://localhost:8001/api/sync/full

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping 113.29.232.245

# è°ƒæ•´åŒæ­¥é…ç½®
nano config/distributed_ha_config.yaml
# ä¿®æ”¹ sync_interval å’Œ sync_batch_size
```

#### 4. APIæœåŠ¡æ— æ³•è®¿é—®

**ç—‡çŠ¶**: æ— æ³•è®¿é—®APIç«¯ç‚¹

**è¯Šæ–­æ­¥éª¤**:
```bash
# æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
ps aux | grep python
ps aux | grep uvicorn

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep 8000
netstat -tlnp | grep 8001

# æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¼€æ”¾ç«¯å£
sudo ufw allow 8000
sudo ufw allow 8001

# é‡å¯APIæœåŠ¡
pkill -f "uvicorn"
python start_simple_ha.py
```

#### 5. å†…å­˜ä¸è¶³é—®é¢˜

**ç—‡çŠ¶**: ç³»ç»Ÿè¿è¡Œç¼“æ…¢æˆ–å´©æºƒ

**è¯Šæ–­æ­¥éª¤**:
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
top -p $(pgrep -f python)

# æ£€æŸ¥æ—¥å¿—ä¸­çš„å†…å­˜é”™è¯¯
grep -i "memory\|oom" logs/simple_ha.log
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# è°ƒæ•´è¿æ¥æ± å¤§å°
nano config/distributed_ha_config.yaml
# å‡å°‘ max_connections å’Œ pool_size

# å¢åŠ ç³»ç»Ÿäº¤æ¢ç©ºé—´
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_images_created_at ON images(created_at);
CREATE INDEX idx_images_url_hash ON images(md5(url));

-- ä¼˜åŒ–PostgreSQLé…ç½®
-- åœ¨ postgresql.conf ä¸­æ·»åŠ :
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
```

#### 2. ç½‘ç»œä¼˜åŒ–

```bash
# è°ƒæ•´TCPå‚æ•°
echo 'net.core.rmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_rmem = 4096 87380 16777216' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_wmem = 4096 65536 16777216' >> /etc/sysctl.conf
sysctl -p
```

#### 3. åº”ç”¨ç¨‹åºä¼˜åŒ–

```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´å¹¶å‘å‚æ•°
crawler:
  max_concurrent: 5  # å‡å°‘å¹¶å‘æ•°
  request_delay: 2   # å¢åŠ è¯·æ±‚å»¶è¿Ÿ

synchronization:
  sync_batch_size: 50  # å‡å°‘æ‰¹æ¬¡å¤§å°
  sync_interval: 10    # å¢åŠ åŒæ­¥é—´éš”
```

---

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### ç³»ç»Ÿç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor_system.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

echo "=== ç³»ç»ŸçŠ¶æ€ç›‘æ§ ==="
echo "æ—¶é—´: $(date)"
echo

# æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
echo "1. è¿›ç¨‹çŠ¶æ€:"
if pgrep -f "start_simple_ha.py" > /dev/null; then
    echo "âœ… HAç³»ç»Ÿè¿è¡Œä¸­"
else
    echo "âŒ HAç³»ç»Ÿæœªè¿è¡Œ"
fi

# æ£€æŸ¥APIæœåŠ¡
echo "2. APIæœåŠ¡çŠ¶æ€:"
if curl -s http://localhost:8000/api/ha-status > /dev/null; then
    echo "âœ… ä¸»APIæœåŠ¡æ­£å¸¸"
else
    echo "âŒ ä¸»APIæœåŠ¡å¼‚å¸¸"
fi

if curl -s http://localhost:8001/api/status > /dev/null; then
    echo "âœ… HA APIæœåŠ¡æ­£å¸¸"
else
    echo "âŒ HA APIæœåŠ¡å¼‚å¸¸"
fi

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "3. æ•°æ®åº“è¿æ¥:"
python3 -c "
import psycopg2
try:
    conn = psycopg2.connect('postgresql://postgres:Abcdefg6@113.29.231.99:5432/image_crawler')
    print('âœ… ä¸»æ•°æ®åº“è¿æ¥æ­£å¸¸')
    conn.close()
except:
    print('âŒ ä¸»æ•°æ®åº“è¿æ¥å¼‚å¸¸')

try:
    conn = psycopg2.connect('postgresql://postgres:Abcdefg6@113.29.232.245:5432/image_crawler')
    print('âœ… å¤‡æ•°æ®åº“è¿æ¥æ­£å¸¸')
    conn.close()
except:
    print('âŒ å¤‡æ•°æ®åº“è¿æ¥å¼‚å¸¸')
"

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "4. ç£ç›˜ç©ºé—´:"
df -h | grep -E "/$|/data"

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo "5. å†…å­˜ä½¿ç”¨:"
free -h

echo "=== ç›‘æ§å®Œæˆ ==="
```

### è‡ªåŠ¨åŒ–ç»´æŠ¤è„šæœ¬

```bash
#!/bin/bash
# maintenance.sh - è‡ªåŠ¨åŒ–ç»´æŠ¤è„šæœ¬

# æ¸…ç†æ—§æ—¥å¿—
find logs/ -name "*.log" -mtime +7 -delete

# æ¸…ç†æ—§å¤‡ä»½
find data/backup/ -name "*.sql" -mtime +30 -delete

# æ•°æ®åº“ç»´æŠ¤
psql -h 113.29.231.99 -U postgres -d image_crawler -c "VACUUM ANALYZE;"
psql -h 113.29.232.245 -U postgres -d image_crawler -c "VACUUM ANALYZE;"

# é‡å¯æœåŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [ "$1" = "restart" ]; then
    pkill -f "start_simple_ha.py"
    sleep 5
    nohup python start_simple_ha.py > logs/startup.log 2>&1 &
fi

echo "ç»´æŠ¤ä»»åŠ¡å®Œæˆ: $(date)"
```

### å®šæ—¶ä»»åŠ¡é…ç½®

```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯5åˆ†é’Ÿæ£€æŸ¥ç³»ç»ŸçŠ¶æ€
*/5 * * * * /opt/image_crawler/monitor_system.sh >> /var/log/system_monitor.log

# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œç»´æŠ¤ä»»åŠ¡
0 2 * * * /opt/image_crawler/maintenance.sh

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹é‡å¯ç³»ç»Ÿ
0 3 * * 0 /opt/image_crawler/maintenance.sh restart
```

---

## ğŸ†˜ ç´§æ€¥æ¢å¤ç¨‹åº

### æ•°æ®æ¢å¤

```bash
# ä»å¤‡ä»½æ¢å¤æ•°æ®åº“
pg_restore -h 113.29.231.99 -U postgres -d image_crawler data/backup/latest_backup.sql

# é‡å»ºç´¢å¼•
psql -h 113.29.231.99 -U postgres -d image_crawler -c "REINDEX DATABASE image_crawler;"
```

### ç³»ç»Ÿé‡ç½®

```bash
# åœæ­¢æ‰€æœ‰æœåŠ¡
pkill -f "start_simple_ha.py"
pkill -f "uvicorn"

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf logs/*.log
rm -rf data/temp/*

# é‡æ–°åˆå§‹åŒ–æ•°æ®åº“
python setup_postgresql_databases.py --reset

# é‡å¯ç³»ç»Ÿ
python start_simple_ha.py
```

---

æœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„éƒ¨ç½²æµç¨‹å’Œæ•…éšœæ’æŸ¥æ–¹æ³•ï¼Œå¸®åŠ©å¿«é€Ÿéƒ¨ç½²å’Œç»´æŠ¤å›¾åƒçˆ¬è™«åˆ†å¸ƒå¼é«˜å¯ç”¨ç³»ç»Ÿã€‚é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æŒ‰ç…§è¯Šæ–­æ­¥éª¤é€æ­¥æ’æŸ¥ï¼Œå¹¶å‚è€ƒè§£å†³æ–¹æ¡ˆè¿›è¡Œä¿®å¤ã€‚
