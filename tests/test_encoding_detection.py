#!/usr/bin/env python3
"""
æµ‹è¯•ç¼–ç æ£€æµ‹åŠŸèƒ½
"""

import asyncio
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from crawler.core.async_crawler import AsyncCrawler

def test_encoding_detection():
    """æµ‹è¯•ç¼–ç æ£€æµ‹åŠŸèƒ½"""
    
    print("ğŸ”¤ æµ‹è¯•ç¼–ç æ£€æµ‹åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = AsyncCrawler({})
    
    # æµ‹è¯•ä¸åŒç¼–ç çš„å†…å®¹
    test_cases = [
        {
            'name': 'UTF-8 with BOM',
            'content': b'\xef\xbb\xbf<html><head><meta charset="utf-8"></head><body>Hello World</body></html>',
            'expected': 'utf-8-sig'
        },
        {
            'name': 'UTF-8 without BOM',
            'content': '<html><head><meta charset="utf-8"></head><body>Hello ä¸–ç•Œ</body></html>'.encode('utf-8'),
            'expected': 'utf-8'
        },
        {
            'name': 'GBK encoding',
            'content': '<html><head><meta charset="gbk"></head><body>ä½ å¥½ä¸–ç•Œ</body></html>'.encode('gbk'),
            'expected': 'gbk'
        },
        {
            'name': 'GB2312 encoding',
            'content': '<html><head><meta charset="gb2312"></head><body>ä¸­æ–‡æµ‹è¯•</body></html>'.encode('gb2312'),
            'expected': 'gb2312'
        },
        {
            'name': 'HTML meta charset',
            'content': b'<html><head><meta http-equiv="Content-Type" content="text/html; charset=gbk"></head><body>\xc4\xe3\xba\xc3</body></html>',
            'expected': 'gbk'
        },
        {
            'name': 'XML encoding declaration',
            'content': b'<?xml version="1.0" encoding="gb2312"?><root>\xd6\xd0\xce\xc4</root>',
            'expected': 'gb2312'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {case['name']}")
        print(f"   å†…å®¹é•¿åº¦: {len(case['content'])} å­—èŠ‚")
        
        # æ£€æµ‹ç¼–ç 
        detected = crawler._detect_encoding(case['content'])
        expected = case['expected']
        
        print(f"   æœŸæœ›ç¼–ç : {expected}")
        print(f"   æ£€æµ‹ç¼–ç : {detected}")
        
        if detected == expected:
            print(f"   âœ… æ£€æµ‹æ­£ç¡®")
        elif detected and detected.replace('-', '').replace('_', '') == expected.replace('-', '').replace('_', ''):
            print(f"   âœ… æ£€æµ‹æ­£ç¡® (ç¼–ç åç§°å˜ä½“)")
        else:
            print(f"   âŒ æ£€æµ‹é”™è¯¯")
        
        # å°è¯•è§£ç éªŒè¯
        if detected:
            try:
                decoded = case['content'].decode(detected)
                print(f"   âœ… è§£ç æˆåŠŸ: {len(decoded)} å­—ç¬¦")
            except Exception as e:
                print(f"   âŒ è§£ç å¤±è´¥: {e}")
        else:
            print(f"   âŒ æœªæ£€æµ‹åˆ°ç¼–ç ")
    
    print("\n" + "=" * 50)
    print("ğŸ ç¼–ç æ£€æµ‹æµ‹è¯•å®Œæˆ")

async def test_real_gbk_website():
    """æµ‹è¯•çœŸå®çš„GBKç½‘ç«™"""
    
    print("\nğŸŒ æµ‹è¯•çœŸå®GBKç½‘ç«™")
    print("=" * 50)
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = AsyncCrawler({
        'max_depth': 1,
        'max_images': 10,
        'max_concurrent': 5
    })
    
    # æµ‹è¯•GBKç¼–ç çš„ä¸­æ–‡ç½‘ç«™
    test_urls = [
        'http://www.netbian.com/',  # ç½‘ç«™ä½¿ç”¨GBKç¼–ç 
    ]
    
    for url in test_urls:
        print(f"\nğŸ” æµ‹è¯•ç½‘ç«™: {url}")
        print("-" * 30)
        
        try:
            result = await crawler.start_crawling(url)
            
            if result.get('success', False):
                stats = result.get('stats', {})
                print(f"âœ… çˆ¬å–æˆåŠŸ:")
                print(f"   é¡µé¢æ•°: {stats.get('pages_crawled', 0)}")
                print(f"   å‘ç°å›¾ç‰‡: {stats.get('images_found', 0)}")
                print(f"   ä¸‹è½½æˆåŠŸ: {stats.get('images_downloaded', 0)}")
                print(f"   è€—æ—¶: {stats.get('duration', 0):.2f}ç§’")
            else:
                print(f"âŒ çˆ¬å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ çœŸå®ç½‘ç«™æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    # æµ‹è¯•ç¼–ç æ£€æµ‹
    test_encoding_detection()
    
    # æµ‹è¯•çœŸå®ç½‘ç«™
    asyncio.run(test_real_gbk_website())
